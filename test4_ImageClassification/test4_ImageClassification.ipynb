{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4cc1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制前十张图像\n",
    "def data_show(dataAll,label):\n",
    "    plt.figure() # 新建画布，防止堆叠\n",
    "    for i in range(1,11):\n",
    "        plt.subplot(1,10,i)\n",
    "        data = dataAll[i, :]    #i为第几个数据\n",
    "        data = data.reshape(28, 28)  #将数据转为（28，28）维度\n",
    "        img = Image.fromarray(data)  #转为图片\n",
    "        plt.imshow(img)\n",
    "    plt.title(label)\n",
    "    plt.show()\n",
    "\n",
    "# 加载数据\n",
    "def data_load(dataName):\n",
    "    path = \"data/quick_draw_data/\"\n",
    "    dataAll = np.load(path + dataName+\"/\"+dataName+\".npy\")\n",
    "#     data_show(dataAll, dataName)\n",
    "    return dataAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b260e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用方法读取数据\n",
    "apple = data_load(\"apple\")\n",
    "ambulance = data_load(\"ambulance\")\n",
    "bear = data_load(\"bear\")\n",
    "bicycle = data_load(\"bicycle\")\n",
    "bird = data_load(\"bird\")\n",
    "bus = data_load(\"bus\")\n",
    "cat = data_load(\"cat\")\n",
    "foot = data_load(\"foot\")\n",
    "owl = data_load(\"owl\")\n",
    "pig = data_load(\"pig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f0d6c0",
   "metadata": {},
   "source": [
    "# 构建CNN（例如Alex net）作为10-分类模型\n",
    "\n",
    "Alexnet由八层网络构成，其中包括5层卷积层和3层全连接层。卷积层包含了卷积、激活、池化、局部归一化几个过程，全连接层包括了droupout、激活、全连接几个过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2093e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f457e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建AlexNet网络变体作为分类器\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,num_classes=10,init_weights=False):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # 特征提取层，padding填充\n",
    "#             输出大小 = ((输入大小 - 卷积核大小) / 步长) + 1\n",
    "            nn.Conv2d(1,20,kernel_size=3,stride=3,padding=2), # Input[28，28，1]    output[10,10,20]\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            \n",
    "            nn.Conv2d(20, 40, kernel_size=3, stride=1,padding=1),  # input[10,10,20]  output[8,8,40]\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(40, 40, kernel_size=3, stride=1,padding=1),  # input[8,8,40]  output[6,6,40]\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            # 全连接层\n",
    "            nn.Dropout(p=0.5),  # p:神经元随机失活的比例\n",
    "            \n",
    "            nn.Linear(6*6*40,500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(500,num_classes)  # num_classes：分类的类别数\n",
    "        )\n",
    "\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    # 前向过程\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)  # 特征提取层\n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "        x = self.classifier(x)  # 全连接+分类\n",
    "        return x\n",
    "\n",
    "    # 初始化权重\n",
    "    def _initialize_weights(self):\n",
    "        # 遍历整个modules\n",
    "        for m in self.modules():\n",
    "            # 发现有nn.Conv2d这个结构\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                # 凯明初始化权重\n",
    "                nn.init.kaiming_normal_(m.weight,mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            # 发现有nn.Linear，则使用正态分布初始化函数\n",
    "            elif isinstance(m,nn.Linear):\n",
    "                nn.init.normal_(m.weight,0,0.01)\n",
    "                nn.init.constant_(m.bias,0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec90a9",
   "metadata": {},
   "source": [
    "# 训练模型\n",
    "每类数据按照6:3:1方式划分训练集、验证集、测试集对模型进行训练，绘制训练过程中损失函数和预测acc曲线（在同一幅图中）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3146c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "\n",
    "# 数据划分\n",
    "def data_split(arr):\n",
    "    # 按比例6:3:1随机划分数组\n",
    "\n",
    "    # 随机打乱数组顺序\n",
    "    np.random.shuffle(arr)\n",
    "\n",
    "    # 计算划分点的索引\n",
    "    split1 = int(len(arr) * 0.7)\n",
    "    split2 = int(len(arr) * 0.9)\n",
    "\n",
    "    # 按比例6:3:1划分数组\n",
    "    split_arr = np.split(arr, [split1, split2])\n",
    "    return split_arr\n",
    "\n",
    "\n",
    "label_names=['ambulance','apple','bear','bicycle','bird','bus','cat','foot','owl','pig']\n",
    "\n",
    "# 存放不同类别的训练集、验证集、测试集\n",
    "train = {}\n",
    "val = {}\n",
    "test = {}\n",
    "\n",
    "for i in range(0,10):\n",
    "    arr = locals()[label_names[i]]  # 依据标签名定位数据\n",
    "    train[i],val[i],test[i] = data_split(arr)  # i即为标签索引\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38a88ee6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_get_cpp_backtrace' from 'torch._C' (D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_C.cp310-win_amd64.pyd)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optim\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# from torch.utils.data import Dataset,DataLoader\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtransforms\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\__init__.py:6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodulefinder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Module\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datasets, io, models, ops, transforms, utils\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mextension\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _HAS_OPS\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malexnet\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconvnext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdensenet\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mefficientnet\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\convnext.py:8\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn, Tensor\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m functional \u001B[38;5;28;01mas\u001B[39;00m F\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmisc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Conv2dNormActivation, Permute\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstochastic_depth\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StochasticDepth\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_presets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ImageClassification\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\ops\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_register_onnx_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _register_custom_op\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mboxes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      3\u001B[0m     batched_nms,\n\u001B[0;32m      4\u001B[0m     box_area,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     13\u001B[0m     remove_small_boxes,\n\u001B[0;32m     14\u001B[0m )\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mciou_loss\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m complete_box_iou_loss\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\ops\\_register_onnx_ops.py:5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m symbolic_opset11 \u001B[38;5;28;01mas\u001B[39;00m opset11\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msymbolic_helper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse_args\n\u001B[0;32m      8\u001B[0m _ONNX_OPSET_VERSION_11 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m11\u001B[39m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\onnx\\symbolic_opset11.py:12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _C\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_C\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _onnx \u001B[38;5;28;01mas\u001B[39;00m _C_onnx\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     13\u001B[0m     _type_utils,\n\u001B[0;32m     14\u001B[0m     errors,\n\u001B[0;32m     15\u001B[0m     symbolic_helper,\n\u001B[0;32m     16\u001B[0m     symbolic_opset10 \u001B[38;5;28;01mas\u001B[39;00m opset10,\n\u001B[0;32m     17\u001B[0m     symbolic_opset9 \u001B[38;5;28;01mas\u001B[39;00m opset9,\n\u001B[0;32m     18\u001B[0m     utils,\n\u001B[0;32m     19\u001B[0m )\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_globals\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GLOBALS\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_internal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _beartype, jit_utils, registration\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\onnx\\_type_utils.py:10\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_C\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _onnx \u001B[38;5;28;01mas\u001B[39;00m _C_onnx\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m errors\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_internal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _beartype\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typing\u001B[38;5;241m.\u001B[39mTYPE_CHECKING:\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;66;03m# Hack to help mypy to recognize torch._C.Value\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\onnx\\errors.py:9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _C\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _constants\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_internal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m diagnostics\n\u001B[0;32m     11\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnnxExporterError\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnnxExporterWarning\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSymbolicValueError\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     18\u001B[0m ]\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mOnnxExporterWarning\u001B[39;00m(\u001B[38;5;167;01mUserWarning\u001B[39;00m):\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\onnx\\_internal\\diagnostics\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_diagnostic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      2\u001B[0m     create_export_diagnostic_context,\n\u001B[0;32m      3\u001B[0m     diagnose,\n\u001B[0;32m      4\u001B[0m     engine,\n\u001B[0;32m      5\u001B[0m     export_context,\n\u001B[0;32m      6\u001B[0m     ExportDiagnostic,\n\u001B[0;32m      7\u001B[0m )\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_rules\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m rules\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minfra\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m levels\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\onnx\\_internal\\diagnostics\\_diagnostic.py:11\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_internal\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdiagnostics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m infra\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cpp_backtrace\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cpp_call_stack\u001B[39m(frames_to_skip: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m, frames_to_log: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m32\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m infra\u001B[38;5;241m.\u001B[39mStack:\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;124;03m\"\"\"Returns the current C++ call stack.\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03m    This function utilizes `torch.utils.cpp_backtrace` to get the current C++ call stack.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     21\u001B[0m \n\u001B[0;32m     22\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\cpp_backtrace.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_C\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _get_cpp_backtrace\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_cpp_backtrace\u001B[39m(frames_to_skip\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, maximum_number_of_frames\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m    Returns a string containing the C++ stack trace of the current thread.\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;124;03m        frames_to_skip (int): the number of frames to skip from the top of the stack\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;124;03m        maximum_number_of_frames (int): the maximum number of frames to return\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name '_get_cpp_backtrace' from 'torch._C' (D:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_C.cp310-win_amd64.pyd)"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import interpolate\n",
    "from torch import optim\n",
    "# from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6105e2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(train[i])):\n\u001B[1;32m---> 16\u001B[0m         train_tensor[i][j] \u001B[38;5;241m=\u001B[39m \u001B[43mtransf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m val_tensor \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n",
      "Cell \u001B[1;32mIn[16], line 5\u001B[0m, in \u001B[0;36mtransf\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m      3\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(data) \u001B[38;5;66;03m#转为图片\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# 定义变换\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m transform \u001B[38;5;241m=\u001B[39m \u001B[43mtransforms\u001B[49m\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m      6\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mToTensor(),  \u001B[38;5;66;03m# 转换为 torch.Tensor\u001B[39;00m\n\u001B[0;32m      7\u001B[0m ])\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# 进行变换\u001B[39;00m\n\u001B[0;32m     10\u001B[0m tensor_image \u001B[38;5;241m=\u001B[39m transform(image)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "def transf(data):\n",
    "    data = data.reshape(28, 28)#将数据转为（28，28）维度\n",
    "    img = Image.fromarray(data) #转为图片\n",
    "    # 定义变换\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # 转换为 torch.Tensor\n",
    "    ])\n",
    "\n",
    "    # 进行变换\n",
    "    tensor_image = transform(img)\n",
    "    return tensor_image\n",
    "\n",
    "train_tensor = {}\n",
    "for i in range(10):\n",
    "    for j in range(len(train[i])):\n",
    "        train_tensor[i][j] = transf(train[i][j])\n",
    "        \n",
    "val_tensor = {}\n",
    "for i in range(10):\n",
    "    for j in range(len(val[i])):\n",
    "        val_tensor[i][j] = transf(val[i][j])\n",
    "        \n",
    "test_tensor = {}\n",
    "for i in range(10):\n",
    "    for j in range(len(test[i])):\n",
    "        test_tensor[i][j] = transf(test[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c8aa646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算模型准确度\n",
    "def test(model):\n",
    "    # 批量数目\n",
    "    batch_size = 10\n",
    "    # 预测正确个数\n",
    "    correct = 0\n",
    "    \n",
    "    # 从验证集加载200个数据进行验证\n",
    "    for i in range(10):\n",
    "        for j in np.random.sample(range(0,len(test[0])),20):\n",
    "            # 预测\n",
    "            prediction = model(test_tensor[i][j]))\n",
    "            # 将预测值中最大的索引取出，其对应了不同类别值\n",
    "            predicted = torch.max(prediction.data, 1)[1]\n",
    "            # 获取准确个数\n",
    "            if predict == i:\n",
    "                correct+=1\n",
    "    acc = correct / 200        \n",
    "#     print('准确率: %d' % (correct / 200)) # 因为总共500个测试数据\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "031ada35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练过程\n",
    "def model_train():\n",
    "    batch_size = 16     # 批量训练大小\n",
    "    model = Net() # 创建模型\n",
    "    \n",
    "    # 定义损失函数\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    # 定义优化器\n",
    "    optimizer = optim.Adam(params=model.parameters(),lr=0.0002)\n",
    "    \n",
    "    # 定义损失和准确度\n",
    "    loss = []\n",
    "    acc = []\n",
    "    \n",
    "    for n in range(0,10): # 10个epoch\n",
    "        print(\"epoch [%d]\" % n)\n",
    "        loss_temp = 0  # 临时变量\n",
    "        \n",
    "        for i in range(0,len(train[0])):\n",
    "            for j in range(0,10):\n",
    "                # 梯度清零\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # 模型训练\n",
    "                prediction = model(train_tensor[i][j])\n",
    "                # 损失值\n",
    "                loss = loss_func(prediction,j)\n",
    "                loss_temp += loss.item()\n",
    "                # 反向传播\n",
    "                loss.backward()\n",
    "                # 梯度更新\n",
    "                optimizer.step()\n",
    "        if  ((i+1)%100)==0 :\n",
    "            # 打印一次损失值\n",
    "            print('loss: %.3f' % (loss_temp/1000))\n",
    "            loss.append(loss_temp/1000)\n",
    "            # 打印一次准确度\n",
    "            acc_temp = test(model)\n",
    "            acc.append(acc_temp)\n",
    "    return model,loss,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e75f3fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [784]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model,loss,acc \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[12], line 25\u001B[0m, in \u001B[0;36mmodel_train\u001B[1;34m()\u001B[0m\n\u001B[0;32m     22\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# 模型训练\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# 损失值\u001B[39;00m\n\u001B[0;32m     27\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_func(prediction,j)\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[4], line 38\u001B[0m, in \u001B[0;36mNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m,x):\n\u001B[1;32m---> 38\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 特征提取层\u001B[39;00m\n\u001B[0;32m     39\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mflatten(x,start_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     40\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier(x)  \u001B[38;5;66;03m# 全连接+分类\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 139\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:457\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    456\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 457\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    450\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    451\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    452\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [784]"
     ]
    }
   ],
   "source": [
    "model,loss,acc = model_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6ea84",
   "metadata": {},
   "source": [
    "# 验证模型\n",
    "从每类数据的测试集中随机抽取10张图片进行预测，输出该图像的标签以及预测概率分布的柱状图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0ce29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
